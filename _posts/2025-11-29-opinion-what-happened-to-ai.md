---
layout: post
title:  "Opinion: What Happened to AI?"
author: julia
editor: medha
comments: false
categories:
  - opinion
  - technology
image: assets/images/opinion_what_happened_to_ai_header.avif
tags:
  - featured
---
Just months ago, people started talking about how over-dependence on AI could lead to the end of the world. However, after the release of GPT-5, and recent reports from companies such as IBM, AI has not continued on the path that it has in the past. As such, I wanted to revisit the actual impact AI has had on the productivity of software companies and what jobs AI could realistically replace as of now to probe whether a robot uprising is imminent.

First of all, a perpetual fear that has struck many job-seekers is of “AI-based coding agents.” Tools like Replit’s AI Agent can generate both front-end and back-end code with little to no human input, yet they often lack true direction when building even simple web applications.For example, if a person wanted to code a simple frontend web application with a Natural Language Processing or Large Language Model using Replit’s agent, in many cases Replit can completely erase files when asked to “debug.” 

This issue isn’t unique to Replit. Other AI coding tools, such as Gemini (integrated into Google Colab), GitHub Copilot, and VSCode have very similar issues that are not addressed by the developers of the models. The core challenge lies in how these large language models operate: they break down user instructions and attempt to generate code based on patterns and associations learned from internet data. Because of this, AI can easily make mistakes or hallucinations, since it does not actually understand what the code means in context. 

I would like to argue that while AI is very popular right now for its generative capabilities, it does not boast a large amount of skills that could be more beneficial for a company compared to actual human coders. This is because AI was initially developed as a mathematical model for image and speech recognition. Early AI systems focused on analyzing data, such as speech recognition models that could identify and interpret spoken language. Over time, these foundational models evolved into applications like Google Translate, which was based on early “transformer” architectures—taking in input and instructions to generate the best output that it could. 

While this technology was initially only for Translation models and sorting large amounts of images and numerical data, this soon expanded away from just “Translation” and into mainstream generative AI. This era started with the release of GPT-3, a model that changed the way thousands of people saw AI. Before that, not many people could directly interact with AI. But ChatGPT was a chatbot that the mainstream could experience and realize how intelligent AI could seem. However, they did not know the significant limitations and risks that come with its use.

The first major problem with AI emerged when people started over-relying on it, beginning in 2022 with OpenAI’s release of ChatGPT. Now in 2025, OpenAI has become one of the largest startups in the United States. Because of OpenAI’s success, companies started to copy their business model by creating their own generative AI tools, creating what is now often called the AI bubble. 

Investment bubbles like this are not new—and they often end in crashes. For example, the 2007 stock market crash was fueled by risky mortgage lending practices that promised affordable housing but trapped homebuyers with high-interest loans, ultimately triggering the Great Recession. This was caused essentially by the overinvestment in something that cost a lot of money. Similarly, in the 1990s, the rise of the internet made many people assume that this technology was going to make them extremely wealthy if they invested right then. As such, a large number of people invested in technology stocks. By the early 2000s, other financial crises caused many technology companies to have large amounts of collateral, so the companies that overestimated the stability of the market and overinvested had to declare bankruptcy. This is just another example of what companies can do when a technology, or some sort of profitable product or business model, is over-promoted, which can cause a complete collapse of that industry later. 

The same pattern seems to be repeating today with AI. As generative AI gained popularity, companies rushed to adopt it—not necessarily because it improved their products or efficiency, but because it was new and seemed more advanced than previous technologies. This concept can be related to a number of different companies, which have used ChatGPT-like technology to sell their products, including products that generate code or give grammar advice. 

One such company, Cresta AI, is an AI agent company that sells the idea of a “more efficient experience” at call centers worldwide. Valued at around $282 million, Cresta AI is primarily marketed for companies and call centers nationwide that may want more callers, while decreasing the number of workers in such industries. However, as we can learn from past bubbles, this is most likely not going to last forever, and soon, the AI bubble too may burst.

Recently, AI has started to not just generate code, but also has started to replace human jobs. In 2024, IBM, a long-established leader in the technology industry, announced that AI had replaced over 94 percent of its human resources (HR) tasks, with AI likely to replace more work in the future. This shift has displaced many workers and raised an important question: _Is it really sustainable for AI to be replacing humans?_ Such a question brought a group of protesters together outside OpenAI in San Francisco, California, in April 2025 to voice fears about the consequences of widespread AI adoption. However, _could our overreliance on AI actually be preventing companies from completing productive work?&#xA0;_

In a blog post titled “Simulated Company Shows Most AI Agents Flunk the Job,” researchers from Carnegie Mellon University conducted a study that tested how well AI agents could perform in a simulated workplace. The experiment simulated a company with easy, medium, and hard tasks, and the AI models were evaluated based on how many they successfully completed. The highest-performing model, Anthropic’s Claude, only completed 24% of the available tasks, whereas other models, such as OpenAI’s GPT-4-o, only accomplished 8% of these tasks. These findings show us that these models are not ready to replace humans, which, as this article mentions, should relieve a number of corporate workers that their jobs will be unlikely to be replaced soon. This study also shows us that generative AI workers will be much less effective, causing companies that use them in most software engineering jobs to be at a clear disadvantage. Finally, this study shows us that most tools, such as AI agents for Vibe Coding that promise to be more professional than normal coding tools, are much less effective than what was advertised. Overall, if companies place blind trust in AI systems, they risk serious setbacks in productivity and performance across the software industry.

To conclude, while AI models, such as neural networks, have been around for decades, the 2022 release of ChatGPT 3-o, a Generative AI model, caused a large number of people to become exposed to Artificial Intelligence, which caused a new investment bubble, the AI bubble. This led to a growing belief that AI would start stealing jobs. However, factual evidence around this claim lacks evidence besides personal biases, and in fact, for many tasks, such as programming, humans are still exponentially better than Artificial Intelligence tools. Therefore, it is important to re-examine most arguments that AI will steal jobs, when many investment bubbles had a very similar boom, where the product that was being advertised was nowhere near the level of effectiveness that it did. Now that you understand AI a little bit more, hopefully, you can tell if a product, such as an AI coding agent, will actually help you.

**Sources:**

[_header image_](https://unsplash.com/photos/a-computer-screen-with-a-bunch-of-code-on-it-ieic5Tq8YMk)_&#x20;used under the Unsplash License_

[_www.cs.cmu.edu/news/2025/agent-company._](http://www.cs.cmu.edu/news/2025/agent-company)

[_www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality._](http://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality)

[_www.kqed.org/news/12051183/protesters-against-ai-militarization-rally-at-scale-ai-in-san-francisco_](http://www.kqed.org/news/12051183/protesters-against-ai-militarization-rally-at-scale-ai-in-san-francisco)

[_www.aseonline.org/News-Events/Articles/hr-transformed-ibm-cuts-hr-jobs-as-ai-takes-over-routine-tasks_](http://www.aseonline.org/News-Events/Articles/hr-transformed-ibm-cuts-hr-jobs-as-ai-takes-over-routine-tasks)

[_www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/_](http://www.whitehouse.gov/presidential-actions/2025/07/accelerating-federal-permitting-of-data-center-infrastructure/)

[_www.federalreservehistory.org/essays/great-recession-and-its-aftermath_](http://www.federalreservehistory.org/essays/great-recession-and-its-aftermath)

[_https://startupsavant.com/startups-to-watch/ai_](https://startupsavant.com/startups-to-watch/ai)